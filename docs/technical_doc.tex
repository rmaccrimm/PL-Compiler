\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{centernot}
\usepackage{listings, lstautogobble}
\usepackage[export]{adjustbox}
\usepackage[T1]{fontenc}
\usepackage{courier}

\let\bf\textbf
\let\it\textit
\newcommand{\der}{$\longrightarrow$ }
\newcommand{\es}{$\varepsilon$ }
\newcommand{\alt}{\Large$|$ \normalsize }

\begin{document}

\title{CPSC 4600 Project Language (PL) Compiler \\ \LARGE Technical Documentation}
\author{Roderick MacCrimmon \\ Spring 2019}
\date{}
\maketitle

\section{Purpose}

The purpose of this program, in its current state, is to perform the scanning and parsing stages of compilation for a single PL source file and perform basic error detection. The input file is parsed into tokens, which are stored in an output text file. When an invalid identifier, numeral or other character is detected, an error message is printed to the console along with the line in which the error occurred. The sequence of tokens is then passed to the parser, which verifies that the sequence is valid according to the language grammar (given at the end of this document). As the parser runs, the call stack, representing the parse tree, is printed. If a syntax error is encountered, a message containing the line on which the error occurred and the problematic token is printed and the program terminates.

\section{Design}

\subsection*{Data Types}

\begin{itemize}
    \item[] \textbf{Symbol}
        \begin{itemize}
            \item[-] an enumeration type containing values for every  token in the PL language including keywords, identifiers, special symbols, newline, etc.
        \end{itemize} 
    \item[] \textbf{Token} 
        \begin{itemize}
            \item[-] A simple class with symbol, lexeme, and value data members. They symbol is one of the values described above, lexeme is the actual text contained in the source file, and value is an integer currently only used to store the value of numerals (integer literals).
        \item[-] Only member functions are a default constructor, copy constructor and assignment operator 
        \end{itemize} 

\end{itemize}

\subsection*{Classes}

    \begin{itemize}
        \item[]\textbf{SymbolTable} 
            \begin{itemize}
                \item[-] A hash table used to store identifier tokens. The table is initialized with all reserved words tokens to provide an easy method of determining if a scanned word is reserved. The hash function used is  Contains a vector of c++ unique\_ptrs for creating new tokens (unique\_ptr used to avoid the need for explicit deletion) and the following operations:
                \item[-] \textbf{contains}: check if an entry exists in the table for the given key
                \item[-] \textbf{insert} insert a new element with they given key
                \item[-] \textbf{get} retrieve the token with given key
                \item[-] hashing is implemented by the private method \textbf{hash\_fn} which uses the djb2 hash function found online at http://www.cse.yorku.ca/~oz/hash.html. Uses linear probing to handle collisions
            \end{itemize}

        \item[]\textbf{Scanner}
            \begin{itemize}
                \item[-] Performs the lexical analysis on the input program. The constructor takes a reference to an input file stream object as input, from which it will read the input program, and a reference to a symbol table object into which identifier tokens will be inserted. 
                \item[-] \textbf{get\_token}: the only public method, which returns the next token in the input file until it reaches the end of the file. All subsequent calls will return an end of file token.
                \item[-] contains a large number of private methods for parsing the input text. Anything that begins with a letter is considered a word and must follow the pattern letter (letter | \_ | digit$^*$). Anything beginning with a digit is considered a numeral and must follow the pattern (digit)$^+$. Other symbols are considered individually. 
                \item[-]Tokens are also returned for invalid words, numerals and symbols and unrecognized characters. 
            \end{itemize}

        \item[]\textbf{Parser}
            \begin{itemize}
                \item[-] Verifies the input token sequence represents a valid PL program by constructing the parse tree according to the PL language grammar.
                \item[-] \textbf{verify\_syntax}: Only public method, parses the input sequence. Uses predictive parsing with the recursive descent parsing technique. The class contains a private method corresponding to every non-terminal of the grammar, parsing is started by calling the program method. For a given production rule $A \longrightarrow B_1B_2B_3...$ the method for $A$ works by calling match($B_i$) if $B_i$ is a terminal symbol (token) or calling the method for $B_i$ if it is a non-terminal.
                \item[-] When multiple production rules are available, the correct one is chosen by checking if the lookahead token (next\_token) is contained in the rule's FIRST set. If the production derives the empty string, the FOLLOW set is checked instead. Both sets have been determined by hand and are hard-coded into the functions. If none of the available production rules can correctly derive the lookahead token, a syntax error is thrown, which currently just prints an error message and crashes the program.
                \item[-] \textbf{match}: Checks that the lookahead token matches the expected terminal symbol and advances to the next token in the input.
            \end{itemize}

        \item[]\textbf{Compiler}
            \begin{itemize}
                \item[-] The main "Administration" class which is responsible for creating, managing and using the other component objects. Currently stores scanner and symbol table objects. The constructor takes a reference to an input file stream object as input, which is used to create the scanner object. 
                \item[-] \textbf{scan}: there are two versions of this method that differ only in their output. One will write tokens to the provided output file stream in the format \textit{symbol-name lexeme value} (space-separated) while the other will simply fill a vector of tokens. Only the first is currently used.  
                \item[-] Both scan methods make calls to the private \textbf{tokenize} method which repeatedly calls scanner's get\_token method until an end of file token is returned. Any time an error token is returned, the rest of the line is ignored. A line count is also maintained by incrementing every time a newline token is seen in order to output error messages which identify where errors occurred
            \end{itemize}

    \end{itemize}

    \section{Limitations/Possible Extensions}

        \subsection{Part II}

        Currently the most lacking part of the parser is in error handling, as the program simply crashes on an invalid program with minimal information given in the error message. Implementing proper panic-mode error handling would be the most obvious next step, skipping input tokens until some point is found from which parsing can continue. It would also be helpful to output more meaningful error messages, such as what was expected to be seen, and using the actual lexemes rather than symbol names. 

        Another possible extension of the parser would be to explicitly produce the parse tree and store it in some sort of tree data structure. This could potentially be useful in producing error messages or in panic-mode error handling. If nothing is found that can follow the current non-terminal, the parser could move back up the tree, looking for something that could follow at any point. A formal parse table could also be constructed, reducing the need for searching first and follow sets, and formally verifying the language is LL(1), excluding the one ambiguity with identifiers.

        Testing is also currently very limited and the parser has only been verified on one program taken from the Brinch Hansen book. Before the next stage I plan to implement some unit tests and try to verify that every control path is followed as expected. 

        \subsection{Part I}

        Implementing the rest of the compiler will be the most important thing going forward, but there are some improvements that could be made to the scanner as well. Tokens currently take up more space than they need to by always having a lexeme and a value. For many tokens all we need is the symbol name for it to serve its purpose. While this is a pretty minor improvement, there could be multiple types of tokens inherited from a base class for word tokens, numeral tokens, etc. that only have as much info as needed. Since I already use a table of token pointers in the symbol table, incorporating this polymorphism would be fairly straightforward. Additionally, all lexemes could be stored in a buffer and only an index would be needed in the token rather than the full string.

        One current issue with the scanner is that it does not enforce the PL limitation wherein only the first ten characters of an identifier are meaningful. While removing this limitation seems like an upgrade, it is not true to the PL language specification. This condition should be straightforward to implement but will require some additional testing.

        Another improvement that could be made is to implement the scanner in a way that more closely resembles a finite-state automaton, rather than with the current conditional based approach I'm using. This would make rigorously describing it's output easier and likely be less prone to bugs, though maybe more difficult or tedious to implement.


    \pagebreak
    \section{PL Grammar}
    The PL context-free grammar has been slightly modified form the Brinch Hansesn book, and written without the use of extended BNF notation below.

    \begin{itemize}[label={}]
        \itemsep-0.3em
        \item Program \der Block \bf .
        \item Block \der \bf{begin} DefinitionPart StatementPart \bf{end}
        \item DefnPart \der Defn \bf ; DefnPart \alt \es
        \item Defn \der ConstDefn \alt VarDefn \alt ProcDefn
        \item ConstDefn \der \bf{const} \bf{identifier} $=$ Constant
        \item VarDefn \der Type VarDefnType
        \item VarDefnType \der VarList \alt \bf{array} VarList [ Constant ]
        \item Type \der \bf{integer} \alt \bf {Boolean}
        \item VarList \der \bf{identifier} VarListEnd
        \item VarListEnd \der \bf, \bf{identifier} VarListEnd \alt \es
        \item ProcDefn \der \bf{proc} \bf{identifier} Block
        \item StmtPart \der Stmt \bf ; StmtPart \alt \es
        \item Stmt \der EmptyStmt \alt ReadStmt \alt WriteStmt \alt AssignStmt \alt ProcStmt \alt IfStmt \alt DoStmt
        \item EmptyStmt \der \bf{skip}
        \item ReadStmt \der \bf{read} VarAccessList
        \item VarAccessList \der VarAccess VarAccessListEnd
        \item VarAccessListEnd \der \bf , VarAccess VarAccessListEnd \alt \es
        \item WriteStmt \der \bf{write} ExpressionList
        \item ExpressionList \der Expression ExpressionListEnd
        \item ExpressionListEnd \der \bf, Expression ExpressionListEnd \alt \es 
        \item AssignStmt \der VarAccessList \bf{:=} ExpressionList
        \item ProcStmt \der \bf{call} \bf{identifier}
        \item IfStmt \der \bf{if} GuardedCmdList \bf{fi}
        \item DoStmt \der \bf{do} GuardedCmdList \bf{od}
        \item GuardedCmdList \der GuardedCmd GuardedCmdListEnd
        \item GuardedCmdListEnd \der [ ] GuardedCmd GuardedCmdListEnd \alt \es
        \item GuardedCmd \der Expression -$>$ StmtPart
        \item Expression \der PrimaryExpression ExpressionEnd
        \item ExpressionEnd \der PrimaryOp PrimaryExpression ExpressionEnd \alt \es
        \item PrimaryOp \der $\&$ \alt $|$
        \item PrimaryExpression \der SimpleExpression PrimaryExpressionEnd
        \item PrimaryExpressionEnd \der RelationalOp SimpleExpression \alt \es
        \item RelationalOp \der $<$ \alt $=$ \alt $>$
        \item SimpleExpression \der $-$ Term SimpleExpressionEnd \alt Term SimpleExpressionEnd
        \item SimpleExpressionEnd \der AdditionOp Term SimpleExpressionEnd \alt \es
        \item AdditionOp \der $+$ \alt $-$
        \item Term \der Factor TermEnd
        \item TermEnd \der MultiplicationOp Factor TermEnd \alt \es
        \item MultiplicationOp \der $*$ \alt \textbackslash\: \alt $/$ 
        \item Factor \der Constant \alt VarAccess \alt ( Expression ) \alt $\sim$ Factor
        \item VarAccess \der \bf{identifier} VarAccessEnd 
        \item VarAccessEnd \der IndexedSelector \alt \es
        \item IndexedSelector \der [ Expression ]
        \item Constant \der \bf{numeral} \alt \bf{true} \alt \bf{false} \alt \bf{identifier}
    \end{itemize}

\end{document}