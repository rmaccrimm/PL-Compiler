\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{centernot}
\usepackage{listings, lstautogobble}
\usepackage[export]{adjustbox}
\usepackage[T1]{fontenc}
\usepackage{courier}

\let\bf\textbf
\let\it\textit
\newcommand{\der}{$\longrightarrow$ }
\newcommand{\es}{$\varepsilon$ }
\newcommand{\alt}{\Large$|$ \normalsize }

\begin{document}

\title{CPSC 4600 Project Language (PL) Compiler \\ \LARGE Technical Documentation}
\author{Roderick MacCrimmon \\ Spring 2019}
\date{}
\maketitle

\section{Purpose}

The purpose of this program is to translate a program written in the project language (PL) to PL assembly (PLAM) code to be assembled by the provided assembler and then run on a PLAM interpreter, and to perform basic syntax and semantics checking and error recovery. This includes lexical analysis, which converts the input source file to a sequence of tokens, parsing, which verifies the program is valid according to the language grammar (given at the end of this document), and code generation, which outputs PLAM code. 

\subsection{Error Handling}

There are four main types of error detection which occur, and all aim to provide useful error messages as well as allow compilation to continue. The first type of error that may occurr is a lexical, or scanning, error which occurs when invalid symbols are found in the input. If these kinds of errors are found, compilation will not continue as the input file can not be converted to a sequence of tokens. Next are syntax errors. When these are encountered, the program attempts to recover by entering panic mode. During panic mode input symbols are skipped until a sequencing symbol is found (a member of the follow set for the current non terminal), from which point parsing resumes. If no such symbols are found, the program will eventually throw an end of file error and exit. 

While parsing, the scope and type of all identifiers and expressions are deduced in order to ensure variables are not used before they are defined, not redefined within the same scope, and that the types are compatible with the operations being done. Only a single error of this type is produced per expression, so there are not redundant error messages being given for the same expression. Parsing otherwise continues as normal when these errors are encountered.

\section{Design}

\subsection*{Data Types}

\begin{itemize}
    \item[] \textbf{Symbol}
        \begin{itemize}
            \item[-] an enumeration type containing values for every  token in the PL language including keywords, identifiers, special symbols, newline, etc.
        \end{itemize} 
    \item[] \textbf{Token} 
        \begin{itemize}
            \item[-] A simple class with symbol, lexeme, and value data members. They symbol is one of the values described above, lexeme is the actual text contained in the source file, and value is an integer currently only used to store the value of numerals (integer literals).
        \item[-] Only member functions are a default constructor, copy constructor and assignment operator 
        \end{itemize} 
    \item[] \textbf{PLType}
        \begin{itemize}
            \item[-] An enumeration type containing the valid "kinds" of variables that an identifier or expression can represent. These are Boolean variable, Boolean constant, integer variable, integer constant, procedure, and undefined. During parsing, the type of each identifier and literal are deduced to check for consistency.
        \end{itemize}
    \item[] \textbf{BlockData}
        \begin{itemize}
            \item[-] A data-only struct containing elements to be stored in Blocks in the BlockTable. Represent variables and include information about the size, type, value, and logical adresses of variables.
        \end{itemize}
\end{itemize}

\subsection*{Classes}

    \begin{itemize}
        \item[]\textbf{SymbolTable} 
            \begin{itemize}
                \item[-] A hash table used to store identifier tokens. The table is initialized with all reserved words tokens to provide an easy method of determining if a scanned word is reserved. The hash function used is  Contains a vector of c++ unique\_ptrs for creating new tokens (unique\_ptr used to avoid the need for explicit deletion) and the following operations:
                \item[-] \textbf{contains}: check if an entry exists in the table for the given key
                \item[-] \textbf{insert} insert a new element with they given key
                \item[-] \textbf{get} retrieve the token with given key
                \item[-] hashing is implemented by the private method \textbf{hash\_fn} which uses the djb2 hash function found online at http://www.cse.yorku.ca/~oz/hash.html. Uses linear probing to handle collisions
            \end{itemize}

        \item[]\textbf{Scanner}
            \begin{itemize}
                \item[-] Performs the lexical analysis on the input program. The constructor takes a reference to an input file stream object as input, from which it will read the input program, and a reference to a symbol table object into which identifier tokens will be inserted. 
                \item[-] \textbf{get\_token}: the only public method, which returns the next token in the input file until it reaches the end of the file. All subsequent calls will return an end of file token.
                \item[-] contains a large number of private methods for parsing the input text. Anything that begins with a letter is considered a word and must follow the pattern letter (letter | \_ | digit$^*$). Anything beginning with a digit is considered a numeral and must follow the pattern (digit)$^+$. Other symbols are considered individually. 
                \item[-]Tokens are also returned for invalid words, numerals and symbols and unrecognized characters. 
            \end{itemize}

        \item[]\textbf{Parser}
            \begin{itemize}
                \item[-] Verifies the input token sequence represents a valid PL program by constructing the parse tree according to the PL language grammar. Also performs type and scope analysis, ensuring that variables are defined before used and not redefined, and that the types of variables (integer or Boolean) used in expressions are compatible.
                \item[-] \textbf{verify\_syntax}: Only public method, parses the input sequence and returns the number of errors encountered. Uses predictive parsing with the recursive descent parsing technique. The class contains a private method corresponding to every non-terminal of the grammar, parsing is started by calling the program method. For a given production rule $A \longrightarrow B_1B_2B_3...$ the method for $A$ works by calling match($B_i$) if $B_i$ is a terminal symbol (token) or calling the method for $B_i$ if it is a non-terminal.
                \item[-] When multiple production rules are available, the correct one is chosen by checking if the lookahead token (next\_token) is contained in the rule's FIRST set. If the production derives the empty string, the FOLLOW set is checked instead.
                \item[-] \textbf{match}: Checks that the lookahead token matches the expected terminal symbol and advances to the next token in the input.
                \item[-] \textbf{synchronize}: Whenever a syntax error is encountered, the program utilizes a panic-mode error recovery strategy. This function consults the follow set of the non-terminal in which the error occurred, to find a point from which parsing is likely to be able to continue. Input tokens are ignored until something in the follow set is found. 
                \item[-] When a syntax error occurs, an error message is printed containing the line and name of the problematic symbol. The point from which parsing continued following the synchronize method is also printed. Scope and type errors produce an error message, but parsing just continues as normal (often leading to many redundant error messages). 
                \item[-] \textbf{Block table}: Scope and type checking make use of a block table, which is a stack containing "blocks" which are maps from identifiers to block data - the variable type and size. Every time a new block is entered (anywhere begin is found in the program) a new block is pushed onto the stack, and is intially a copy of the block preceding it. This makes all variables accessible within nested blocks (procedures), but not the other way around - variables defined within a procedure are not accessible outside it. This also means variables within a block cannot share a name with any variables in the outer scope.
            \end{itemize}

        \item[]\textbf{Compiler}
            \begin{itemize}
                \item[-] The main "Administration" class which is responsible for creating, managing and using the other component objects. Currently stores scanner and symbol table objects. The constructor takes a reference to an input file stream object as input, which is used to create the scanner object. 
                \item[-] \textbf{run}: Compiler's only public method. Uses the tokenize method to create a list of tokens using the scanner get\_token method. If scanning completes without errors, the token list is passed to the parser to be analyzed.
                \item[-] \textbf{tokenize}: private method - uses the scanner object to construct a token list and detect invalid characters. When an error is encountered, an error message is produced and the rest of the line ignored. If any errors are encountered during this stage of compilation, parsing will not occur.
            \end{itemize}

    \end{itemize}

    \section{Limitations/Possible Extensions}

        \subsection{Part IV}

        \subsection{Part III}

        At this point the compiler seems to be fairly robust, in terms of handling any sort of input without crashing and producing relevant error messages. The error messages themselves are the main thing that could be improved, as they currently point to a line of the program and the general sort of error (mismatch between types, undefined variable) but they could be more specific in some cases and provide more information on the state of the system, such as deduced variable types, which specific variable within a comma separated l,list, etc. Additionally a lot of error messages are redundant, since a scope error usually leads to a variable having undefined type, which causes a type error immediately after. 

        The panic-mode error handling, while often succesful in continuing parsing, also tends to very quickly reach the end of file while skipping input, making only the first syntax error message very meaningful. Some other approach to constructing synchronization sets that is more specific to this grammar might be worth attempting. 

        Overall code quality improvements could be made in a number of places, making the compiler easier to extend and improve. One thing in particular would be the introduction of some kind of error handling class, which might help cut back on the length of the parser class and help implement some of the error message improvements mentioned above.

        \subsection{Part II}

        Currently the most lacking part of the parser is in error handling, as the program simply crashes on an invalid program with minimal information given in the error message. Implementing proper panic-mode error handling would be the most obvious next step, skipping input tokens until some point is found from which parsing can continue. It would also be helpful to output more meaningful error messages, such as what was expected to be seen, and using the actual lexemes rather than symbol names. 

        Another possible extension of the parser would be to explicitly produce the parse tree and store it in some sort of tree data structure. This could potentially be useful in producing error messages or in panic-mode error handling. If nothing is found that can follow the current non-terminal, the parser could move back up the tree, looking for something that could follow at any point. A formal parse table could also be constructed, reducing the need for searching first and follow sets, and formally verifying the language is LL(1), excluding the one ambiguity with identifiers.

        Testing is also currently very limited and the parser has only been verified on one program taken from the Brinch Hansen book. Before the next stage I plan to implement some unit tests and try to verify that every control path is followed as expected. 

        \subsection{Part I}

        Implementing the rest of the compiler will be the most important thing going forward, but there are some improvements that could be made to the scanner as well. Tokens currently take up more space than they need to by always having a lexeme and a value. For many tokens all we need is the symbol name for it to serve its purpose. While this is a pretty minor improvement, there could be multiple types of tokens inherited from a base class for word tokens, numeral tokens, etc. that only have as much info as needed. Since I already use a table of token pointers in the symbol table, incorporating this polymorphism would be fairly straightforward. Additionally, all lexemes could be stored in a buffer and only an index would be needed in the token rather than the full string.

        One current issue with the scanner is that it does not enforce the PL limitation wherein only the first ten characters of an identifier are meaningful. While removing this limitation seems like an upgrade, it is not true to the PL language specification. This condition should be straightforward to implement but will require some additional testing.

        Another improvement that could be made is to implement the scanner in a way that more closely resembles a finite-state automaton, rather than with the current conditional based approach I'm using. This would make rigorously describing it's output easier and likely be less prone to bugs, though maybe more difficult or tedious to implement.


    \pagebreak
    \section{PL Grammar}
    The PL context-free grammar has been slightly modified form the Brinch Hansesn book, and written without the use of extended BNF notation below.

    \begin{itemize}[label={}]
        \itemsep-0.3em
        \item Program \der Block \bf .
        \item Block \der \bf{begin} DefinitionPart StatementPart \bf{end}
        \item DefnPart \der Defn \bf ; DefnPart \alt \es
        \item Defn \der ConstDefn \alt VarDefn \alt ProcDefn
        \item ConstDefn \der \bf{const} \bf{identifier} $=$ Constant
        \item VarDefn \der Type VarDefnType
        \item VarDefnType \der VarList \alt \bf{array} VarList [ Constant ]
        \item Type \der \bf{integer} \alt \bf {Boolean}
        \item VarList \der \bf{identifier} VarListEnd
        \item VarListEnd \der \bf, \bf{identifier} VarListEnd \alt \es
        \item ProcDefn \der \bf{proc} \bf{identifier} Block
        \item StmtPart \der Stmt \bf ; StmtPart \alt \es
        \item Stmt \der EmptyStmt \alt ReadStmt \alt WriteStmt \alt AssignStmt \alt ProcStmt \alt IfStmt \alt DoStmt
        \item EmptyStmt \der \bf{skip}
        \item ReadStmt \der \bf{read} VarAccessList
        \item VarAccessList \der VarAccess VarAccessListEnd
        \item VarAccessListEnd \der \bf , VarAccess VarAccessListEnd \alt \es
        \item WriteStmt \der \bf{write} ExpressionList
        \item ExpressionList \der Expression ExpressionListEnd
        \item ExpressionListEnd \der \bf, Expression ExpressionListEnd \alt \es 
        \item AssignStmt \der VarAccessList \bf{:=} ExpressionList
        \item ProcStmt \der \bf{call} \bf{identifier}
        \item IfStmt \der \bf{if} GuardedCmdList \bf{fi}
        \item DoStmt \der \bf{do} GuardedCmdList \bf{od}
        \item GuardedCmdList \der GuardedCmd GuardedCmdListEnd
        \item GuardedCmdListEnd \der [ ] GuardedCmd GuardedCmdListEnd \alt \es
        \item GuardedCmd \der Expression -$>$ StmtPart
        \item Expression \der PrimaryExpression ExpressionEnd
        \item ExpressionEnd \der PrimaryOp PrimaryExpression ExpressionEnd \alt \es
        \item PrimaryOp \der $\&$ \alt $|$
        \item PrimaryExpression \der SimpleExpression PrimaryExpressionEnd
        \item PrimaryExpressionEnd \der RelationalOp SimpleExpression \alt \es
        \item RelationalOp \der $<$ \alt $=$ \alt $>$
        \item SimpleExpression \der $-$ Term SimpleExpressionEnd \alt Term SimpleExpressionEnd
        \item SimpleExpressionEnd \der AdditionOp Term SimpleExpressionEnd \alt \es
        \item AdditionOp \der $+$ \alt $-$
        \item Term \der Factor TermEnd
        \item TermEnd \der MultiplicationOp Factor TermEnd \alt \es
        \item MultiplicationOp \der $*$ \alt \textbackslash\: \alt $/$ 
        \item Factor \der Constant \alt VarAccess \alt ( Expression ) \alt $\sim$ Factor
        \item VarAccess \der \bf{identifier} VarAccessEnd 
        \item VarAccessEnd \der IndexedSelector \alt \es
        \item IndexedSelector \der [ Expression ]
        \item Constant \der \bf{numeral} \alt \bf{true} \alt \bf{false} \alt \bf{identifier}
    \end{itemize}

\end{document}